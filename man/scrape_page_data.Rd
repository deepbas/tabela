% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/script.R
\name{scrape_page_data}
\alias{scrape_page_data}
\title{Scrape and summarize downloadable files + (optional) HTML tables}
\usage{
scrape_page_data(
  root_url,
  exts = c("csv", "txt", "xlsx", "sav", "por", "RData"),
  page = 1,
  page_size = 10,
  list_tables = FALSE
)
}
\arguments{
\item{root_url}{Character. Page to scrape.}

\item{exts}{Character vector of extensions (no dot). Defaults include csv, txt, xlsx, sav, por, RData.}

\item{page}{Integer. Batch number for pagination (1 = first page_size links).}

\item{page_size}{Integer. Number of file-links per page. Default 10.}

\item{list_tables}{Logical. If TRUE, also extract all HTML tables as data.frames.}
}
\value{
A list with elements:
\itemize{
\item $files: tibble of file info (name,url,type,rows,cols, ...)
\item $tables (optional): list of HTML tables
}
}
\description{
Scrape and summarize downloadable files + (optional) HTML tables
}
